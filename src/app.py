import streamlit as st
import pandas as pd
import tabula
import joblib
import tensorflow as tf
import openai
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Fraud-Detect",
    page_icon="üí≥",
    initial_sidebar_state="expanded",
  
)

# Estilo CSS para el centrado de la tabla
st.write("""
    <style>
    .st-emotion-cache-x1xsqf + .st-emotion-cache-x1xsqf + .st-emotion-cache-x1xsqf + .st-emotion-cache-x1xsqf + .st-emotion-cache-x1xsqf + .st-emotion-cache-x1xsqf + .st-emotion-cache-x1xsqf + .st-emotion-cache-x1xsqf + .st-emotion-cache-x1xsqf {
    width: 100%;
    display: flex;
    justify-content: center;
}
    </style>
""", unsafe_allow_html=True)
# Estilo CSS para el t√≠tulo
st.image("img/banner.webp", use_column_width=True, output_format='auto')
st.markdown("""
   <style>
   .title {
      text-align: center;
      color: #1D3557;
   }
   
   </style>
""", unsafe_allow_html=True)



# inicio de fraud detect
st.markdown("<h1 class='title'>Fraud-Detect</h1>", unsafe_allow_html=True)



# Breve descripci√≥n de la aplicaci√≥n
st.write("**Fraud Detect** es una aplicaci√≥n web dise√±ada para abordar de manera eficiente y precisa la detecci√≥n de posibles fraudes bancarios. Su funcionalidad radica en la capacidad de procesar documentos en formato PDF, extrayendo las tablas contenidas en ellos mediante su lector integrado. A partir de los datos recopilados en estas tablas, la aplicaci√≥n lleva a cabo un exhaustivo an√°lisis para identificar posibles irregularidades financieras que puedan indicar la presencia de actividades fraudulentas entre una lista de clientes. Adem√°s muestra una sucesi√≥n de gr√°ficas con datos que pueden ser de utilidad para el usuario.")

# definici√≥n de columnas del dataset
columnas = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',
            'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',
            'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']

# carga del modelo de detecci√≥n de fraude
modelo = joblib.load('model/modelo_fraud_detect.pkl')

# carga del modelo de clustering
modelo_clustering = joblib.load('model/clustering_fraud_detect.pkl')

# creaci√≥n del dataframe
df = pd.DataFrame(columns=columnas)



# boton de subida de archivos (no hay l√≠mite y se pueden eliminar en la propia p√°gina)
uploaded_files = st.file_uploader("Elige tus archivos PDF", type="pdf", accept_multiple_files=True)
for uploaded_file in uploaded_files:
    if uploaded_file is not None:
        # lectura de las tablas de los archivos
        df_temp_list = tabula.read_pdf(uploaded_file, pages='all')
        for df_temp in df_temp_list:
            # comprueba si es un dataframe
            if isinstance(df_temp, pd.DataFrame):
                # comprueba si tiene las columnas correctas
                if set(columnas).issubset(df_temp.columns):
                    # concatenaci√≥n al dataframe principal
                    df = pd.concat([df, df_temp], ignore_index=True)
                else:
                    st.write(f"El archivo {uploaded_file.name} no tiene las columnas correctas.")
            else:
                # shn kgm
                st.write(f"El archivo {uploaded_file.name} no contiene ninguna tabla.")

# reemplaza las comas por puntos para poder convertir en float
df = df.replace(',', '.', regex=True)

# conversi√≥n de los datos de los archivos a float
df = df.astype(float)

# c√°lculo de la media para poder aplicar el modelo de clustering
columnas_median = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 
                   'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 
                   'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']

df['Median'] = df[columnas_median].mean(axis=1)

# columnas necesarias para la aplicaci√≥n del modelo de clustering
df_clustering = df[['Median', 'Amount']]

# conversi√≥n de dataframe a tensor
df_tensor = tf.convert_to_tensor(df[columnas].values, dtype=tf.float32)  # Solo selecciona las columnas originales aqu√≠

df_clustering_tensor = tf.convert_to_tensor(df_clustering.values, dtype=tf.float32)

st.divider()

# aplicaci√≥n de los modelos
if not df.empty:
   # Switcher para mostrar o no las gr√°ficas
   on = st.toggle('Mostrar las gr√°ficas')
   df['Class'] = modelo.predict(df_tensor)
   df['Cluster'] = modelo_clustering.predict(df_clustering_tensor)

   # creaci√≥n del dataframe para guardar los resultados
   results_df = pd.DataFrame(columns=["Detecci√≥n Fraude", "Cluster"])

   # diccionario para definir las etiquetas de la columna cluster
   cluster_labels = {0: "PG", 1: "LS", 2: "BN", 3: "LN", 4: "IN"}

   # bucle para a√±adir los resultados al dataframe
   for i in range(len(df)):
       new_row = pd.DataFrame({"Detecci√≥n Fraude": ["NO FRAUDE ‚úÖ" if df['Class'][i] == 0 else "FRAUDE ‚ùå"], 
                               "Cluster": [cluster_labels[df['Cluster'][i]]]})
       results_df = pd.concat([results_df, new_row], ignore_index=True)

   st.dataframe(results_df)

   st.divider()

   # gr√°fica que relaciona la predicci√≥n con los clusters (sorted para que salgan de menor a mayor)
   clusters = sorted(df['Cluster'].unique())

   # diccionario para mapear los n√∫meros del cluster a las etiquetas preferidas
   cluster_labels_2 = {0: "PG", 1: "LS", 2: "BN", 3: "LN", 4: "IN"}

   fig, axs = plt.subplots(1, len(clusters), figsize=(10, 15))

   # definici√≥n de los colores para "Fraud" y "Not Fraud"
   colors = ['darkblue', 'lightblue']

   # se crea una gr√°fica circular por cada cluster
   for i, cluster in enumerate(clusters):
       # filtra el dataframe al cluster pertinente
       df_cluster = df[df['Cluster'] == cluster]

       # conteo de casos de fraude
       fraud_counts = df_cluster['Class'].value_counts()

       # c√°lculo del porcentaje de fraud y not fraud
       not_fraud_percentage = fraud_counts.get(0, 0) / fraud_counts.sum() * 100
       fraud_percentage = 100 - not_fraud_percentage

       # creaci√≥n de las etiquetas
       labels = [f'Fraud {fraud_percentage:.1f}%', f'Not Fraud {not_fraud_percentage:.1f}%']

       # creaci√≥n de la gr√°fica
       axs[i].pie([fraud_percentage, not_fraud_percentage], startangle=90, colors = colors)

       # alternaci√≥n de la posici√≥n de t√≠tulo y leyenda
       if i % 2 == 0:
           axs[i].set_title(cluster_labels_2[cluster], y=1.1)
           axs[i].legend(labels, loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5)
       else:
           axs[i].set_title(cluster_labels_2[cluster], y=-0.1)
           axs[i].legend(labels, loc='lower center', bbox_to_anchor=(0.5, 1.05), fancybox=True, shadow=True, ncol=5)
   
   # Si se enciende se activa la gr√°fica
   if on:
      st.pyplot(fig)
      st.divider()


   # Crea un gr√°fico de dispersi√≥n para visualizar los clusters
   plt.figure(figsize=(10, 6))

   for cluster in df['Cluster'].unique():

       # Filtra los datos por cluster
       cluster_data = df[df['Cluster'] == cluster]

       # Plotea los datos con un color diferente para cada cluster
       plt.scatter(cluster_data['Median'], cluster_data['Amount'], label=f'{cluster_labels_2[cluster]}')

   plt.title('Distribuci√≥n de Transacciones por Clusters')
   plt.xlabel('Mediana de V1-V28')
   plt.ylabel('Amount')
   plt.legend()
    
   # Si se enciende se activa la gr√°fica
   if on:
      st.pyplot(plt)
      st.divider()

else:
   st.write('No se han subido archivos PDF v√°lidos.')


with st.sidebar:
    # inicio del chatbot
    st.markdown("<h1 class='title'>Eto'o Bot</h1>", unsafe_allow_html=True)

    # api key de openai
    openai.api_key = st.secrets["OPENAI_API_KEY"]

    # selecci√≥n del modelo con el que queremos trabajar
    if "openai_model" not in st.session_state:
        # 00475-AEDF-52510-2
        st.session_state["openai_model"] = "gpt-3.5-turbo"

    # inicializaci√≥n del hist√≥rico del chat
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # mostrar los mensajes del hist√≥rico
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # reacci√≥n al input del usuario
    if prompt := st.chat_input("Escriba aqu√≠ su consulta"):
        # muestra el mensaje del usuario en su contenetendor de mensaje
        with st.chat_message("user"):
            st.markdown(prompt)
        # a√±ade el mensaje del usuario al hist√≥rico
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            # placeholder vac√≠o
            message_placeholder = st.empty()
            full_response = ""
            # llamada de la api de openai
            for response in openai.ChatCompletion.create(
                # se pasa el modelo y el hist√≥rico
                model=st.session_state["openai_model"],
                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ],
                # este par√°metro hace que vaya escribiendo poco a poco la respuesta
                stream=True,
            ):
                # se a√±ade una parte de la respuesta del chatbot en cada iteraci√≥n del bucle
                full_response += response.choices[0].delta.get("content", "")
                # ense√±a lo que hay de respuesta
                message_placeholder.markdown(full_response + "| ")
            message_placeholder.markdown(full_response)
        # a√±adido de la respuesta al hist√≥rico
        st.session_state.messages.append({"role": "assistant", "content": full_response})

# Pie de p√°gina con informaci√≥n de los creadores
st.markdown('Creadores:')
st.page_link("https://www.linkedin.com/in/pablo-oller-perez-7995721b2", label="**Pablo Oller P√©rez**")
st.page_link("https://github.com/acscr44", label="**Pablo Santos Quirce**")
st.page_link("https://github.com/pabloquirce23", label="**Alejandro Castillo Carmona**")
